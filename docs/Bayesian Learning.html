<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Bayesian Learning</title>
    <link rel="stylesheet" type="text/css" media="screen" href="normalize.css">
    <!--
    <link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">
    -->
    <link rel="stylesheet" type="text/css" media="screen" href="site.css">
  </head>

  <body>
      <div class="container wrapper post">
      <div class="header">
          <h1 class="site-title"><a href="index.html">Brain Dump</a></h1>
          <div class="site-description">
              <h2>Machine Learning</h2>
          </div>
          <nav class="nav">
              <ul class="flat">
                <li> <a href="index.html">Home</a></li>
                <li> <a href="listing.html">All posts</a></li>
              </ul>
          </nav>

    </div>


    <div class="post-header">
        <h1 class="title">Bayesian Learning</h1>
        <div class="meta">Updated at: 02 May 2019 04:01:02</div>
    </div>
    <div class="markdown">

          

<h2>Introduction</h2>

<p>Bayesian ML calculate explicit probabilities, and are the the most practical for certain type of learning problems.</p>

<p>Useful for understanding probabilities that do not explicitly manipulate probabilities.
Bayesian analysis justifies key design choices in ML algorithms.</p>

<p>Alternative error function: cross entropy.</p>

<p>New instances classified by combining the predictions of multiple hypotheses, weighted by their probabilities.</p>

<p>Bayesian methods can provide a standard of optimal decision making against other practical methods.</p>

<p>Require the probabilities to be known in advance, else they are estimated based on background knowledge.</p>

<h3>Naive Bayes:</h3>

<p>Family of simple probabilisitic classifiers based on applying Baye&rsquo;s theorem with strong independence assumptions between the features.</p>

<h2>Possible hypotheses to learn</h2>

<ol>
<li><strong>maximum a posteriori hypothesis</strong>: maximally probable hypothesis</li>
<li><strong>maximum likelihood</strong>: likelihood of data given hypothesis</li>
</ol>

<h2>Bayes Optimal Classifier</h2>

<p>Finding the most probable classification given the training data.</p>

<h2>Gibbs</h2>

<p>Randomly selecting hypothesis based on existing prob distribution, then classifying based on that hypothesis.</p>

<h2>Naive Bayes</h2>

<p>Each instance x is described by a conjugation of input attributes. Target function can take on any value from finite set V. Learner asked to predict target value/classification of new instance.</p>

<p>Predict target value taht will maximize the probability of classification of this instance.</p>


    </div>
</div>
    <div class="footer">
        by <a href="https://seanngpengnam.com">Sean Ng</a> | <a href="https://github.com/pengnam/BrainDump">source</a>
  </div>
  </body>
</html>
